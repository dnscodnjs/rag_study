from openai import OpenAI  # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ OpenAI í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸
import openai  # ìµœì‹  OpenAI ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©
import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os  # ìš´ì˜ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥ì„ ìœ„í•œ os ëª¨ë“ˆ ì„í¬íŠ¸
import base64  # ì´ë¯¸ì§€ ì¸ì½”ë”©ì„ ìœ„í•œ base64 ëª¨ë“ˆ ì„í¬íŠ¸
import json  # JSON íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ json ëª¨ë“ˆ ì„í¬íŠ¸
from dotenv import load_dotenv  # .env íŒŒì¼ì˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•œ í•¨ìˆ˜ ì„í¬íŠ¸
import hashlib  # íŒŒì¼ í•´ì‹œ ê³„ì‚°ì„ ìœ„í•œ ëª¨ë“ˆ
import io  # ë©”ëª¨ë¦¬ ë‚´ íŒŒì¼ ê°ì²´ ìƒì„±ì„ ìœ„í•œ ëª¨ë“ˆ
from gtts import gTTS  # í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ gTTS ë¼ì´ë¸ŒëŸ¬ë¦¬
import re

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_community.tools import TavilySearchResults
from langchain.tools import tool
from langchain_pinecone import PineconeVectorStore
from langchain.docstore.document import Document
from langchain_core.messages import HumanMessage
from langgraph.prebuilt import create_react_agent
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.types import Command
from pinecone import Pinecone  # ìµœì‹  Pinecone API ì‚¬ìš©
from typing import Literal
from typing_extensions import List

# ==========================================
# ì„¤ì • ë° ì´ˆê¸°í™”
# ==========================================
load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
openai.api_key = os.getenv("OPENAI_API_KEY")

index_name = "kcc"
car_type = "EQS"
IMAGE_PATTERN = r'(https?://\S+\.(?:png|jpg|jpeg|gif))'

embedding = OpenAIEmbeddings(model="text-embedding-3-large")  # ì˜ˆ: text-embedding-ada-002
database = PineconeVectorStore(index_name=index_name, embedding=embedding)
retriever = database.as_retriever(search_kwargs={"k": 3})
llm = ChatOpenAI(model='gpt-3.5-turbo')

st.set_page_config(page_title="KCC Auto Manager", layout="wide")
st.title("KCC Auto Manager")

st.markdown(
    """
    <style>
    @media (max-width: 768px) {
        .responsive-image {
            width: 85% !important;
        }
    }
    @media (min-width: 769px) {
        .responsive-image {
            width: 50% !important;
        }
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ê¸°ë³¸ í—¤ë”, í‘¸í„°, ë©”ë‰´ ìˆ¨ê¸°ê¸°
hide_streamlit_style = """
    <style>
    #MainMenu {visibility: hidden;} /* ì¢Œì¸¡ ìƒë‹¨ í–„ë²„ê±° ë©”ë‰´ */
    header {visibility: hidden;}    /* ìƒë‹¨ í—¤ë” */
    footer {visibility: hidden;}    /* í•˜ë‹¨ í‘¸í„° */
    </style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# session_state ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.title("ğŸ¤—ğŸ’¬ Auto Manager ğŸš—")
    st.subheader("í˜„ì¬ ì°¨ëŸ‰: ë²¤ì¸  S í´ë˜ìŠ¤")
    st.markdown("### ì„¤ì •")
    user_language = st.selectbox("ì‚¬ìš© ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”", ("í•œêµ­ì–´", "English", "Deutsch"))
    st.markdown(f"ì„ íƒëœ ì–¸ì–´: **{user_language}**")
    st.markdown("### ë°”ë¡œê°€ê¸°")
    st.markdown("[ë©”ë¥´ì„¸ë°ìŠ¤-ë²¤ì¸  ê³µì‹ í™ˆí˜ì´ì§€](https://www.mercedes-benz.co.kr/)")
    st.markdown("[ë©”ë¥´ì„¸ë°ìŠ¤-ë²¤ì¸  ê³µì‹ ì‚¬ìš© ë©”ë‰´ì–¼](https://www.mercedes-benz.co.kr/passengercars/services/manuals.html)")

# ==========================================
# Pinecone ì¸ë±ìŠ¤ ì´ˆê¸°í™” ë° ë°ì´í„° ì¸ë±ì‹± í•¨ìˆ˜
# ==========================================
def get_file_hash(filename):
    h = hashlib.sha256()
    with open(filename, 'rb') as f:
        h.update(f.read())
    return h.hexdigest()

def load_stored_hash(hash_file):
    try:
        with open(hash_file, "r", encoding="utf-8") as f:
            return f.read().strip()
    except FileNotFoundError:
        return None

def save_hash(hash_file, hash_value):
    with open(hash_file, "w", encoding="utf-8") as f:
        f.write(hash_value)

def index_data():
    hash_file = "test.json.hash"
    current_hash = get_file_hash("test.json")
    stored_hash = load_stored_hash(hash_file)
    
    if stored_hash != current_hash:
        json_file = "test.json"
        with open(json_file, "r", encoding="utf-8") as f:
            test_data = json.load(f)

            documents = []
            for item in test_data:
                pdf_file = item.get("pdf_file", "")
                structure = item.get("structure", [])

                for i, section in enumerate(structure):
                    title = section.get("title", "")
                    sub_titles = section.get("sub_titles", [])
                    content_text = title 
                    image_paths = []

                    for sub in sub_titles:
                        sub_title = sub.get("title", "")
                        contents = sub.get("contents", [])

                        for content in contents:
                            if content.lower().endswith(('.jpeg', '.jpg', '.png', '.gif')):
                                image_paths.append(content)

                        non_image_contents = [c for c in contents if not c.lower().endswith(('.jpeg', '.jpg', '.png', '.gif'))]
                        content_text += "\n" + sub_title + "\n" + "\n".join(non_image_contents)

                    metadata = {
                        "pdf_file": pdf_file,
                        "section_title": title,
                        "image_paths": json.dumps(image_paths)
                    }
                    documents.append(Document(page_content=content_text, metadata=metadata))
            database.add_documents(documents)
        save_hash(hash_file, current_hash)

pinecone_api_key = os.getenv("PINECONE_API_KEY")
pc = Pinecone(api_key=pinecone_api_key)

# ì¸ë±ìŠ¤ ìƒì„±/í™•ì¸
if index_name not in [idx.name for idx in pc.list_indexes()]:
    pc.create_index(
        name=index_name,
        dimension=3072,
        metric="cosine",
    )
index = pc.Index(index_name)

with st.spinner("ë°ì´í„° ì¸ë±ì‹± ì¤‘..."):
    index_data()

# ==========================================
# LangGraph ì •ì˜
# ==========================================
@tool
def vector_retrieve_tool(query: str) -> List[Document]:
    """Retrieve documents based on the given query."""
    return retriever.invoke(query)

def retrieve_search_node(state: MessagesState) -> Command:
    retrieve_search_agent = create_react_agent(
        llm, 
        tools=[vector_retrieve_tool],
        state_modifier = (
            "You are an expert on Mercedes Benz " + car_type + " car manuals."
            "Please consider the information you provided and reply. Please provide facts, not opinions. Please translate the answers into Korean and print them out."
            "Please refer to the structure below to organize the website information:\n\n"
            "{{ì œëª©}}\n"
            "Example: Mercedes Benz EQS: Driver Display Charge Status Window Function\n\n"
            "{{ì£¼ìš” ì •ë³´}}\n"
            "- Feature Summary and Key Points\n\n"
            "{{ìƒì„¸ ì„¤ëª…}}\n"
            "- Detailed description of features\n\n"
        )
    )
    result = retrieve_search_agent.invoke(state)
    state["retrieve_result"] = result['messages'][-1].content

    # ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ stateì—ì„œ ì¶”ì¶œ (ì²« ë²ˆì§¸ ë©”ì‹œì§€ê°€ HumanMessageë¼ê³  ê°€ì •)
    user_query = state["messages"][0].content
    docs = retriever.invoke(user_query)
    
    displayed_image = None
    for doc in docs:
        meta = doc.metadata
        if "image_paths" in meta and meta["image_paths"]:
            try:
                image_paths = json.loads(meta["image_paths"])
            except Exception:
                image_paths = meta["image_paths"]
            if isinstance(image_paths, list) and len(image_paths) > 0:
                displayed_image = image_paths[0]
                break

    # retrieval ê²°ê³¼ ì•ì— ì´ë¯¸ì§€ ë§í¬(ì¡´ì¬í•  ê²½ìš°) ì¶”ê°€
    state["retrieve_result"] = (displayed_image or "") + '\n\n' + state["retrieve_result"] + "\n"
    
    state.setdefault("messages", []).append(
        HumanMessage(content=state["retrieve_result"], name="retrieve_search")
    )
    return Command(update={'messages': state["messages"]})


def evaluate_node(state: MessagesState) -> Command[Literal['web_search', END]]:
    if state["messages"][-1].content is None:
        st.write("ë‹µë³€ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        return Command(goto='web_search')

    # retrieval ê²°ê³¼ê°€ ì¶©ë¶„í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ LLM í‰ê°€ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰
    eval_prompt = PromptTemplate.from_template(
        "You are an expert on Mercedes Benz " + car_type + " car manuals."
        "Please rate if the retrive results below provide sufficient answers."
        "You must assess that the answers or answers of more than 200 characters are sufficiently consistent with your question."
        "If you don't have enough information to judge, or if you don't provide it in your answer, answer 'yes', and answer no if enough is enough.\n\n"
        "Retrieve Results:\n{result}"
    )
    eval_chain = eval_prompt | llm
    evaluation = eval_chain.invoke({"result": state.get("retrieve_result")})
    if "yes" in evaluation.content.lower():
          st.write("ë‹µë³€ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.")
          return Command(goto='web_search')
    else:
          return Command(goto=END)


def web_search_node(state: MessagesState) -> Command:
    tavily_search_tool = TavilySearchResults(
        max_results=5,
        search_depth="advanced",
        include_answer=True,
        include_raw_content=True,
        include_images=True,
    )

    web_search_agent = create_react_agent(
        llm, 
        tools=[tavily_search_tool],
        state_modifier = (
            "You are an expert on Mercedes Benz " + car_type + " car manuals."
            "Please reply to the website information in detail. Please translate the answer into Korean and print it out."
            "Please refer to the structure below to organize the website information:\n\n"
            "## {{ì œëª©}}\n"
            "Example: Mercedes Benz EQS: Driver Display Charge Status Window Function\n\n"
            "### {{ì£¼ìš” ì •ë³´}}\n"
            "- Feature Summary and Key Points\n\n"
            "### {{ìƒì„¸ ì„¤ëª…}}\n"
            "- Detailed description of the feature. / {{ì¶œì²˜}}: real website link\n\n"
            "Please translate the answer into Korean, separate each item into separate lines and print it out in a good way."
        )
    )

    result = web_search_agent.invoke(state)
    state["web_result"] = result['messages'][-1].content
    state.setdefault("messages", []).append(
        HumanMessage(content=state["web_result"], name="web_search")
    )
    return Command(update={'messages': state["messages"]})


# ê·¸ë˜í”„ êµ¬ì„±
graph_builder = StateGraph(MessagesState)
graph_builder.add_node("retrieve_search", retrieve_search_node)
graph_builder.add_node("evaluate", evaluate_node)
graph_builder.add_node("web_search", web_search_node)

graph_builder.add_edge(START, "retrieve_search")
graph_builder.add_edge("retrieve_search", "evaluate")
graph_builder.add_edge("web_search", END)

graph = graph_builder.compile()

# ==========================================
# LangGraph ê¸°ë°˜ Agent ì‹¤í–‰ í•¨ìˆ˜
# ==========================================
def ask_lang_graph_agent(query):
    return graph.invoke({"messages": [("user", query)]})

# ==========================================
# ì‚¬ìš©ì ì…ë ¥ ë° ì²˜ë¦¬
# ==========================================
# st.chat_inputì— ë³„ë„ keyë¥¼ ë‘ì§€ ì•Šê³ , ë§¤ë²ˆ ë™ì¼ keyë¡œ ì‚¬ìš©
user_prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

with st.expander("ìŒì„± ì…ë ¥ ë° ì´ë¯¸ì§€ ì²¨ë¶€ ì—´ê¸°"):
    audio_file = st.audio_input("ìŒì„±ì„ ë…¹ìŒí•˜ì„¸ìš”")
    uploaded_image = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png", "jpg", "jpeg", "gif"])

# ìŒì„± -> í…ìŠ¤íŠ¸ ë³€í™˜
if audio_file is not None:
    with st.spinner("ìŒì„± ì¸ì‹ ì¤‘..."):
        transcript_result = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            language="ko"
        )
    user_prompt = transcript_result.text

# ì‚¬ìš©ì ì…ë ¥ì´ ì¡´ì¬í•˜ë©´ ì²˜ë¦¬
if user_prompt or uploaded_image:
    combined_prompt = user_prompt or ""
    
    # ì´ë¯¸ì§€ í‘œì‹œ
    if uploaded_image:
        st.image(uploaded_image, width=150, caption="ì²¨ë¶€ëœ ì´ë¯¸ì§€")

    # ì‚¬ìš©ì ì§ˆë¬¸ì„ ëŒ€í™” ê¸°ë¡ì— ì €ì¥ (í…ìŠ¤íŠ¸ë§Œ)
    st.session_state.messages.append({"role": "user", "content": combined_prompt})
    
    # lang_graph ê¸°ë°˜ ì±—ë´‡ Agent ì‹¤í–‰
    with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        response = ask_lang_graph_agent(combined_prompt)
    
    # ìµœì¢… ë‹µë³€ ì¶”ì¶œ
    assistant_response = response["messages"][-1].content

    # ì´ë¯¸ì§€ ë§í¬ ê²€ìƒ‰
    match = re.search(IMAGE_PATTERN, assistant_response, flags=re.IGNORECASE)
    related_image = None
    if match:
        related_image = match.group(0)
        # ë‹µë³€ì—ì„œ ì´ë¯¸ì§€ URL ì œê±°
        assistant_response = re.sub(IMAGE_PATTERN, '', assistant_response, count=1, flags=re.IGNORECASE)
    
    # TTS ì²˜ë¦¬
    if assistant_response.strip():
        try:
            tts = gTTS(assistant_response, lang='ko')
            audio_fp = io.BytesIO()
            tts.write_to_fp(audio_fp)
            audio_fp.seek(0)
            audio_bytes = audio_fp.getvalue()
            tts_audio_b64 = base64.b64encode(audio_bytes).decode("utf-8")
        except Exception as tts_error:
            st.error(f"TTS ì—ëŸ¬: {tts_error}")
            tts_audio_b64 = None
    else:
        tts_audio_b64 = None

    # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    assistant_message = {
        "role": "assistant",
        "content": assistant_response,
        "tts": tts_audio_b64,
    }
    if related_image is not None:
        assistant_message["image"] = related_image

    st.session_state.messages.append(assistant_message)

# ==========================================
# ì „ì²´ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
# ==========================================
st.markdown("### ëŒ€í™” ê¸°ë¡")
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # assistant ë©”ì‹œì§€: ê´€ë ¨ ì´ë¯¸ì§€ë¥¼ ë¨¼ì € í‘œì‹œ (ë‹µë³€ ë°”ë¡œ ìœ„ì—)
        if message["role"] == "assistant" and message.get("image"):
            st.markdown(
                f'<img class="responsive-image" src="{message["image"]}" alt="ê´€ë ¨ ì´ë¯¸ì§€">',
                unsafe_allow_html=True
            )

        st.markdown(message["content"])
        # assistant ë©”ì‹œì§€ì— TTSê°€ ì €ì¥ë˜ì–´ ìˆìœ¼ë©´ base64 ë””ì½”ë”© í›„ ì˜¤ë””ì˜¤ ì¶œë ¥
        if message["role"] == "assistant" and message.get("tts"):
            audio_bytes = base64.b64decode(message["tts"])
            st.audio(audio_bytes, format="audio/mp3")
