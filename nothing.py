from openai import OpenAI  # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ OpenAI í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸
import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os  # ìš´ì˜ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥ì„ ìœ„í•œ os ëª¨ë“ˆ ì„í¬íŠ¸
import base64  # ì´ë¯¸ì§€ ì¸ì½”ë”©ì„ ìœ„í•œ base64 ëª¨ë“ˆ ì„í¬íŠ¸
from dotenv import load_dotenv  # .env íŒŒì¼ì˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•œ load_dotenv í•¨ìˆ˜ ì„í¬íŠ¸
import io  # ë©”ëª¨ë¦¬ ë‚´ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì²˜ë¦¬ìš©
import speech_recognition as sr  # ìŒì„± ì¸ì‹ì„ ìœ„í•œ SpeechRecognition ë¼ì´ë¸ŒëŸ¬ë¦¬
from streamlit_audiorecorder import audiorecorder  # ìŒì„± ë…¹ìŒì„ ìœ„í•œ ì»¤ìŠ¤í…€ ì»´í¬ë„ŒíŠ¸

load_dotenv()  # .env íŒŒì¼ì— ì €ì¥ëœ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

# OpenAI API í´ë¼ì´ì–¸íŠ¸ ìƒì„±, í™˜ê²½ë³€ìˆ˜ì—ì„œ OPENAI_API_KEYë¥¼ ì½ì–´ì˜´
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)

st.title("KCC Auto Manager ğŸš—")
st.caption("ìë™ì°¨ ì‚¬ìš© ë§¤ë‰´ì–¼ ë° ì„œë¹„ìŠ¤ ì„¼í„° ìœ„ì¹˜ ì°¾ê¸°ë¥¼ ë„ì™€ë“œë¦½ë‹ˆë‹¤!")

with st.sidebar:
    st.title('ğŸ¤—ğŸ’¬ Auto Manager ğŸš—')

# ì„¸ì…˜ ìƒíƒœì— ëŒ€í™” ê¸°ë¡ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ì´ ìˆë‹¤ë©´ í™”ë©´ì— ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ChatGPTì—ê²Œ ì§ˆë¬¸ì„ ë³´ë‚´ê³  ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ëŠ” í•¨ìˆ˜
def ask_chatgpt_stream(question):
    try:
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì´ì „ ëŒ€í™” ê¸°ë¡(Conversation History)ì„ í¬í•¨í•œ ëŒ€í™” êµ¬ì„±
        conversation = [{"role": "system", "content": "ë„ˆëŠ” ë²¤ì¸  S-class ì‚¬ìš© ë©”ë‰´ì–¼ì— ëŒ€í•´ ì „ë¬¸ê°€ì•¼."}]
        conversation.extend(st.session_state.messages)
        conversation.append({"role": "user", "content": question})
        
        # OpenAIì˜ ChatCompletion API í˜¸ì¶œ (stream=Trueë¡œ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”)
        response = client.chat.completions.create(
            model="o3-mini",  # ì‚¬ìš©í•  ëª¨ë¸ ì§€ì • (ì‚¬ìš©ì¤‘ì¸ ëª¨ë¸ì— ë§ê²Œ ë³€ê²½)
            messages=conversation,
            stream=True  # ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë°›ì•„ì˜´
        )

        answer_container = st.empty()  # ì‹¤ì‹œê°„ ì‘ë‹µ ì¶œë ¥ì„ ìœ„í•œ ë¹ˆ ì»¨í…Œì´ë„ˆ ìƒì„±
        full_response = ""  # ì „ì²´ ì‘ë‹µì„ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²­í¬ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
        for chunk in response:
            if chunk.choices[0].delta.content is not None:
                full_response += chunk.choices[0].delta.content  # ì²­í¬ì˜ í…ìŠ¤íŠ¸ë¥¼ ì „ì²´ ì‘ë‹µì— ì¶”ê°€
                answer_container.markdown(full_response)  # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸í•˜ì—¬ ì¶œë ¥
        return full_response  # ì™„ì„±ëœ ì‘ë‹µ ë°˜í™˜

    except Exception as e:
        st.error(f"Error: {str(e)}")  # ì—ëŸ¬ ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
        return ""

# ===== ì‚¬ìš©ì ì…ë ¥ ì˜ì—­ =====

# 1. í…ìŠ¤íŠ¸ ì…ë ¥
prompt_text = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

# 2. ì´ë¯¸ì§€ ì—…ë¡œë”
uploaded_image = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•˜ì„¸ìš”", type=["png", "jpg", "jpeg", "gif"])

# 3. ìŒì„± ë…¹ìŒ (streamlit-audiorecorder ì‚¬ìš©)
audio_bytes = audiorecorder("ìŒì„± ë…¹ìŒ", "ë…¹ìŒ ì‹œì‘", "ë…¹ìŒ ì¤‘...", "ë…¹ìŒ ì¢…ë£Œ")
voice_text = ""
if audio_bytes:
    st.audio(audio_bytes, format="audio/wav")
    # ìŒì„± ì¸ì‹ì„ ìœ„í•œ Recognizer ìƒì„±
    recognizer = sr.Recognizer()
    try:
        # audio_bytesë¥¼ ë©”ëª¨ë¦¬ ë‚´ íŒŒì¼ ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ ìŒì„± ì¸ì‹
        with sr.AudioFile(io.BytesIO(audio_bytes)) as source:
            audio_data = recognizer.record(source)
        # Google Speech Recognition API ì‚¬ìš© (í•œêµ­ì–´: 'ko-KR')
        voice_text = recognizer.recognize_google(audio_data, language='ko-KR')
        st.markdown(f"**ìŒì„± ì¸ì‹ ê²°ê³¼:** {voice_text}")
    except Exception as e:
        st.error(f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {str(e)}")

# ===== ì…ë ¥ ê²°í•© ë° ì²˜ë¦¬ =====

# í…ìŠ¤íŠ¸ì™€ ìŒì„± ì…ë ¥ì„ ê²°í•© (ë‘˜ ë‹¤ ì¡´ì¬í•  ê²½ìš°)
combined_prompt = ""
if prompt_text:
    combined_prompt += prompt_text
if voice_text:
    if combined_prompt:
        combined_prompt += "\n\nìŒì„± ë©”ì‹œì§€: " + voice_text
    else:
        combined_prompt = voice_text

# ì´ë¯¸ì§€ê°€ ì²¨ë¶€ëœ ê²½ìš°, ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„(ë˜ëŠ” ë°ì´í„°ë¥¼ í™œìš© ê°€ëŠ¥)ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
if uploaded_image is not None:
    # ì´ë¯¸ì§€ ì¸ì‹ì´ ì•„ë‹Œ, ë‹¨ìˆœ ë¯¸ë¦¬ë³´ê¸° ë° ì²¨ë¶€ ì •ë³´ ì „ë‹¬ (ì¶”ê°€ ë¶„ì„ ì‹œ base64 ë³€í™˜ ê°€ëŠ¥)
    combined_prompt += "\n\nì²¨ë¶€ëœ ì´ë¯¸ì§€: " + uploaded_image.name

if combined_prompt:
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": combined_prompt})
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œ (í…ìŠ¤íŠ¸, ìŒì„± ì¸ì‹ ê²°ê³¼, ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°)
    with st.chat_message("user"):
        st.markdown(combined_prompt)
        if uploaded_image is not None:
            st.image(uploaded_image, width=150, caption="ì²¨ë¶€ëœ ì´ë¯¸ì§€")
    
    # ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë°›ì•„ ì¶œë ¥
    with st.chat_message("assistant"):
        response = ask_chatgpt_stream(combined_prompt)
    
    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": response})
