from openai import OpenAI  # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ OpenAI í´ë˜ìŠ¤ ì„í¬íŠ¸
import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os  # OS ëª¨ë“ˆ ì„í¬íŠ¸
from dotenv import load_dotenv  # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ëª¨ë“ˆ

load_dotenv()  # .env íŒŒì¼ì— ì €ì¥ëœ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

# OpenAI API í´ë¼ì´ì–¸íŠ¸ ìƒì„± (í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ì–´ì˜´)
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)

st.title("Simple chat")  # ì•± ì œëª© í‘œì‹œ

# ì„¸ì…˜ ìƒíƒœì— ëŒ€í™” ë‚´ì—­ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì €ì¥ëœ ëŒ€í™” ë‚´ì—­ì„ í™”ë©´ì— ì¶œë ¥ (ì„¸ì…˜ì´ ìœ ì§€ë˜ëŠ” ë™ì•ˆ)
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

def ask_chatgpt_stream(question):
    """
    ChatGPT APIë¥¼ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ í˜¸ì¶œí•˜ì—¬ ì‹¤ì‹œê°„ ì‘ë‹µì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë²¤ì¸  S-class ì‚¬ìš© ë©”ë‰´ì–¼ì— ëŒ€í•´ ì „ë¬¸ê°€ì•¼."},  # ì‹œìŠ¤í…œ ë©”ì‹œì§€
                {"role": "user", "content": question}  # ì‚¬ìš©ì ì§ˆë¬¸
            ],
            stream=True  # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ í™œì„±í™”
        )
        answer_container = st.empty()  # ì‘ë‹µ ì¶œë ¥ì„ ìœ„í•œ ë¹ˆ ì»¨í…Œì´ë„ˆ ìƒì„±
        full_response = ""

        # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‘ë‹µ ì²­í¬ë¥¼ ë°›ì•„ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
        for chunk in response:
            if chunk.choices[0].delta.content is not None:
                full_response += chunk.choices[0].delta.content
                answer_container.markdown(full_response)

        return full_response

    except Exception as e:
        st.error(f"Error: {str(e)}")
    return ""

# ì±„íŒ… ì…ë ¥ê³¼ ì´ë¯¸ì§€ ì²¨ë¶€ ì•„ì´ì½˜ì„ ì˜†ì— ë°°ì¹˜í•˜ê¸° ìœ„í•´ ì»¬ëŸ¼ ì‚¬ìš©
col1, col2 = st.columns([4, 1])
with col1:
    prompt = st.chat_input("What is up?")
with col2:
    # íŒŒì¼ ì—…ë¡œë”ì— "ğŸ“·" ì•„ì´ì½˜ ë¼ë²¨ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì²¨ë¶€ ê°€ëŠ¥ (ì§€ì› í™•ì¥ì: png, jpg, jpeg, gif)
    uploaded_image = st.file_uploader("ğŸ“·", type=["png", "jpg", "jpeg", "gif"], key="img_upload", label_visibility="visible")

if prompt:
    # ì‚¬ìš©ì ì…ë ¥ê³¼ í•¨ê»˜ ì´ë¯¸ì§€ ì²¨ë¶€ ì—¬ë¶€ í™•ì¸
    combined_prompt = prompt
    if uploaded_image is not None:
        # ì´ë¯¸ì§€ê°€ ì²¨ë¶€ëœ ê²½ìš°, ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ì„ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        combined_prompt += "\n\nì²¨ë¶€ëœ ì´ë¯¸ì§€: " + uploaded_image.name

    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ë‚´ì—­ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": combined_prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
        # ì´ë¯¸ì§€ê°€ ì²¨ë¶€ë˜ì—ˆë‹¤ë©´ ë¯¸ë¦¬ë³´ê¸°ë¡œ í‘œì‹œ
        if uploaded_image is not None:
            st.image(uploaded_image, width=150, caption="ì²¨ë¶€ëœ ì´ë¯¸ì§€")

    # Spinnerë¥¼ ë‹µë³€ì´ ì™„ì „íˆ ëë‚  ë•Œê¹Œì§€ í‘œì‹œ
    with st.spinner("ë‹µë³€ì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
        with st.chat_message("assistant"):
            response = ask_chatgpt_stream(combined_prompt)
    st.session_state.messages.append({"role": "assistant", "content": response})
