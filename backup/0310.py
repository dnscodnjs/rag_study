from openai import OpenAI  # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ OpenAI í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸
import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os  # ìš´ì˜ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥ì„ ìœ„í•œ os ëª¨ë“ˆ ì„í¬íŠ¸
import base64  # ì´ë¯¸ì§€ ì¸ì½”ë”©ì„ ìœ„í•œ base64 ëª¨ë“ˆ ì„í¬íŠ¸
from dotenv import load_dotenv  # .env íŒŒì¼ì˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•œ load_dotenv í•¨ìˆ˜ ì„í¬íŠ¸

load_dotenv()  # .env íŒŒì¼ì— ì €ì¥ëœ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

# OpenAI API í´ë¼ì´ì–¸íŠ¸ ìƒì„±, í™˜ê²½ë³€ìˆ˜ì—ì„œ OPENAI_API_KEYë¥¼ ì½ì–´ì˜´
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)

st.title("KCC Auto Manager ğŸš—")
st.caption("ìë™ì°¨ ì‚¬ìš© ë§¤ë‰´ì–¼ ë° ì„œë¹„ìŠ¤ ì„¼í„° ìœ„ì¹˜ ì°¾ê¸°ë¥¼ ë„ì™€ë“œë¦½ë‹ˆë‹¤!")

with st.sidebar:
    st.title('ğŸ¤—ğŸ’¬ Auto Manager ğŸš—')

# ì„¸ì…˜ ìƒíƒœì— ëŒ€í™” ê¸°ë¡ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ì´ ìˆë‹¤ë©´ í™”ë©´ì— ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ChatGPTì—ê²Œ ì§ˆë¬¸ì„ ë³´ë‚´ê³  ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ëŠ” í•¨ìˆ˜
def ask_chatgpt_stream(question):
    try:
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì´ì „ ëŒ€í™” ê¸°ë¡(Conversation History)ì„ í¬í•¨í•œ ëŒ€í™” êµ¬ì„±
        conversation = [{"role": "system", "content": "ë„ˆëŠ” ë²¤ì¸  S-class ì‚¬ìš© ë©”ë‰´ì–¼ì— ëŒ€í•´ ì „ë¬¸ê°€ì•¼."}]
        conversation.extend(st.session_state.messages)
        conversation.append({"role": "user", "content": question})
        
        # OpenAIì˜ ChatCompletion API í˜¸ì¶œ (stream=Trueë¡œ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”)
        response = client.chat.completions.create(
            model="o3-mini",  # ì‚¬ìš©í•  ëª¨ë¸ ì§€ì • (ì‚¬ìš©ì¤‘ì¸ ëª¨ë¸ì— ë§ê²Œ ë³€ê²½)
            messages=conversation,
            stream=True  # ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë°›ì•„ì˜´
        )

        answer_container = st.empty()  # ì‹¤ì‹œê°„ ì‘ë‹µ ì¶œë ¥ì„ ìœ„í•œ ë¹ˆ ì»¨í…Œì´ë„ˆ ìƒì„±
        full_response = ""  # ì „ì²´ ì‘ë‹µì„ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²­í¬ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
        for chunk in response:
            if chunk.choices[0].delta.content is not None:
                full_response += chunk.choices[0].delta.content  # ì²­í¬ì˜ í…ìŠ¤íŠ¸ë¥¼ ì „ì²´ ì‘ë‹µì— ì¶”ê°€
                answer_container.markdown(full_response)  # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸í•˜ì—¬ ì¶œë ¥
        return full_response  # ì™„ì„±ëœ ì‘ë‹µ ë°˜í™˜

    except Exception as e:
        st.error(f"Error: {str(e)}")  # ì—ëŸ¬ ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
        return ""

# ì‚¬ìš©ì ì…ë ¥ì„ ë°›ìŒ (ì±„íŒ… ì…ë ¥ ì°½) ë° ì´ë¯¸ì§€ ì—…ë¡œë” ì¶”ê°€
prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
uploaded_image = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•˜ì„¸ìš”", type=["png", "jpg", "jpeg", "gif"])

# í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ ì…ë ¥ì´ ìˆì„ ë•Œ ì²˜ë¦¬
if prompt or uploaded_image:
    # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì…ë ¥ì„ combined_promptë¡œ ì‚¬ìš©
    combined_prompt = prompt if prompt else ""
    # ì´ë¯¸ì§€ê°€ ì²¨ë¶€ëœ ê²½ìš°, íŒŒì¼ ë°ì´í„°ë¥¼ ì½ì–´ base64ë¡œ ì¸ì½”ë”©í•œ í›„ í…ìŠ¤íŠ¸ì— í¬í•¨
    if uploaded_image is not None:
        image_bytes = uploaded_image.read()
        image_type = uploaded_image.type  # ì˜ˆ: image/jpeg
        image_base64 = base64.b64encode(image_bytes).decode("utf-8")
        # ì´ë¯¸ì§€ ì¸ì‹ ëŒ€ì‹ , ì´ë¯¸ì§€ ë°ì´í„° URLì„ í…ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.
        #combined_prompt += f"\n\nì²¨ë¶€ëœ ì´ë¯¸ì§€: data:{image_type};base64,{image_base64}"

    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": combined_prompt})
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œ (í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°ë„ í‘œì‹œ)
    with st.chat_message("user"):
        if prompt:
            st.markdown(prompt)
        if uploaded_image is not None:
            # ì´ë¯¸ì§€ íŒŒì¼ì„ ë¯¸ë¦¬ë³´ê¸°ë¡œ í‘œì‹œ
            st.image(uploaded_image, width=150, caption="ì²¨ë¶€ëœ ì´ë¯¸ì§€")
    
    # ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë°›ì•„ ì¶œë ¥
    with st.chat_message("assistant"):
        response = ask_chatgpt_stream(combined_prompt)
    
    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µë„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": response})
