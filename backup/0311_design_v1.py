from openai import OpenAI  # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ OpenAI í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸
import openai  # ìµœì‹  OpenAI ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©
import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os  # ìš´ì˜ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥ì„ ìœ„í•œ os ëª¨ë“ˆ ì„í¬íŠ¸
import base64  # ì´ë¯¸ì§€ ì¸ì½”ë”©ì„ ìœ„í•œ base64 ëª¨ë“ˆ ì„í¬íŠ¸
import json  # JSON íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ json ëª¨ë“ˆ ì„í¬íŠ¸
from dotenv import load_dotenv  # .env íŒŒì¼ì˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•œ í•¨ìˆ˜ ì„í¬íŠ¸
from pinecone import Pinecone, ServerlessSpec  # ìµœì‹  Pinecone API ì‚¬ìš©
import hashlib  # íŒŒì¼ í•´ì‹œ ê³„ì‚°ì„ ìœ„í•œ ëª¨ë“ˆ
import io  # ë©”ëª¨ë¦¬ ë‚´ íŒŒì¼ ê°ì²´ ìƒì„±ì„ ìœ„í•œ ëª¨ë“ˆ
from gtts import gTTS  # í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ gTTS ë¼ì´ë¸ŒëŸ¬ë¦¬

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI API ì„¤ì •
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
openai.api_key = os.getenv("OPENAI_API_KEY")

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™” (ìœ„ì ¯ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ uploader_resetì™€ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì €ì¥í•  ë³€ìˆ˜)
if "uploader_reset" not in st.session_state:
    st.session_state["uploader_reset"] = 0
if "uploaded_image_data" not in st.session_state:
    st.session_state["uploaded_image_data"] = None

##########################################
# ë©”ì¸ í™”ë©´
##########################################
st.title("KCC Auto Manager ğŸš—")
st.caption("ìë™ì°¨ ì‚¬ìš© ë§¤ë‰´ì–¼ ë° ì„œë¹„ìŠ¤ ì„¼í„° ìœ„ì¹˜ ì°¾ê¸°ë¥¼ ë„ì™€ë“œë¦½ë‹ˆë‹¤!")

##########################################
# ì‚¬ì´ë“œë°”
##########################################
with st.sidebar:
    st.title("ğŸ¤—ğŸ’¬ Auto Manager ğŸš—")
    st.subheader("í˜„ì¬ ì°¨ëŸ‰: ë²¤ì¸  S í´ë˜ìŠ¤")
    st.markdown("### ëŒ€í™” ì´ë ¥")
    st.markdown("- 1ë²ˆ ëŒ€í™” (2023-01-01)")
    st.markdown("- 2ë²ˆ ëŒ€í™” (2023-01-02)")
    st.markdown("- 3ë²ˆ ëŒ€í™” (2023-01-03)")
    st.markdown("### ì„¤ì •")
    user_language = st.selectbox("ì‚¬ìš© ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”", ("í•œêµ­ì–´", "English", "Deutsch"))
    st.markdown(f"ì„ íƒëœ ì–¸ì–´: **{user_language}**")
    st.markdown("### ë°”ë¡œê°€ê¸°")
    st.markdown("[ë©”ë¥´ì„¸ë°ìŠ¤-ë²¤ì¸  ê³µì‹ í™ˆí˜ì´ì§€](https://www.mercedes-benz.co.kr/)")

##########################################
# Pinecone ì´ˆê¸°í™”
##########################################
pinecone_api_key = os.getenv("PINECONE_API_KEY")
pc = Pinecone(api_key=pinecone_api_key)
index_name = "kcc-new"
if index_name not in [idx.name for idx in pc.list_indexes()]:
    pc.create_index(
        name=index_name,
        dimension=1536,
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )
index = pc.Index(index_name)

##########################################
# ì„ë² ë”© í•¨ìˆ˜ ì •ì˜
##########################################
def get_embedding(text):
    response = openai.embeddings.create(input=[text], model="text-embedding-ada-002")
    return response.data[0].embedding

##########################################
# test.json í•´ì‹œ ë¹„êµ í›„ Pineconeì— ì¸ë±ì‹±
##########################################
def get_file_hash(filename):
    h = hashlib.sha256()
    with open(filename, 'rb') as f:
        h.update(f.read())
    return h.hexdigest()

def load_stored_hash(hash_file):
    try:
        with open(hash_file, "r", encoding="utf-8") as f:
            return f.read().strip()
    except FileNotFoundError:
        return None

def save_hash(hash_file, hash_value):
    with open(hash_file, "w", encoding="utf-8") as f:
        f.write(hash_value)

hash_file = "test.json.hash"
current_hash = get_file_hash("test.json")
stored_hash = load_stored_hash(hash_file)

if stored_hash != current_hash:
    with open("test.json", "r", encoding="utf-8") as f:
        test_data = json.load(f)
    vectors = []
    for item in test_data:
        pdf_file = item.get("pdf_file", "")
        structure = item.get("structure", [])
        for i, section in enumerate(structure):
            title = section.get("title", "")
            sub_titles = section.get("sub_titles", [])
            content_text = title
            image_paths = []
            for sub in sub_titles:
                sub_title = sub.get("title", "")
                contents = sub.get("contents", [])
                for content in contents:
                    if content.lower().endswith(('.jpeg', '.jpg', '.png', '.gif')):
                        image_paths.append(content)
                non_image_contents = [c for c in contents if not c.lower().endswith(('.jpeg', '.jpg', '.png', '.gif'))]
                content_text += "\n" + sub_title + "\n" + "\n".join(non_image_contents)
            doc_id = f"{pdf_file}_{i}"
            embedding = get_embedding(content_text)
            metadata = {
                "pdf_file": pdf_file,
                "section_title": title,
                "content": content_text,
                "image_paths": image_paths
            }
            vectors.append((doc_id, embedding, metadata))
    index.upsert(vectors=vectors)
    save_hash(hash_file, current_hash)
    st.write("Pineconeì— ìƒˆ ë°ì´í„°ë¥¼ ì¸ë±ì‹±í–ˆìŠµë‹ˆë‹¤.")
else:
    st.write("test.json íŒŒì¼ì— ë³€ê²½ì´ ì—†ìœ¼ë¯€ë¡œ, ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

##########################################
# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë° ì¶œë ¥
##########################################
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

##########################################
# ChatGPT ì‘ë‹µ í•¨ìˆ˜ (ìŠ¤íŠ¸ë¦¬ë°)
##########################################
def ask_chatgpt_stream(question, pinecone_context):
    try:
        system_message = (
            "ë„ˆëŠ” ë²¤ì¸  S-class ì‚¬ìš© ë§¤ë‰´ì–¼ì— ëŒ€í•´ ì „ë¬¸ê°€ì•¼. "
            "ì•„ë˜ëŠ” ê´€ë ¨ ë§¤ë‰´ì–¼ ì •ë³´ì…ë‹ˆë‹¤:\n" + pinecone_context
        )
        conversation = [{"role": "system", "content": system_message}]
        conversation.extend(st.session_state.messages)
        conversation.append({"role": "user", "content": question})
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=conversation,
            stream=True
        )
        
        answer_container = st.empty()
        full_response = ""
        for chunk in response:
            if chunk.choices[0].delta.content is not None:
                full_response += chunk.choices[0].delta.content
                answer_container.markdown(full_response)
        return full_response

    except Exception as e:
        st.error(f"Error: {str(e)}")
        return ""

##########################################
# ìƒë‹¨(ê³ ì •) ì˜ì—­: ì´ë¯¸ì§€ ì²¨ë¶€, ì˜¤ë””ì˜¤ ì…ë ¥ (2ì—´)
##########################################
with st.container():
    col1, col2 = st.columns(2)

    with col1:
        uploaded_image = st.file_uploader(
            "ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•˜ì„¸ìš”", 
            type=["png", "jpg", "jpeg", "gif"], 
            key=f"image_uploader_{st.session_state['uploader_reset']}"
        )
        # ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ë©´ session_stateì— ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì €ì¥
        if uploaded_image is not None:
            st.session_state["uploaded_image_data"] = uploaded_image.getvalue()
    with col2:
        audio_file = st.audio_input(
            "ìŒì„± íŒŒì¼ì„ ì²¨ë¶€í•˜ì„¸ìš”", 
            key=f"audio_uploader_{st.session_state['uploader_reset']}"
        )

##########################################
# ì±„íŒ… ì…ë ¥ì°½
##########################################
prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”") or ""
combined_prompt = prompt.strip()

##########################################
# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
##########################################
if prompt or st.session_state.get("uploaded_image_data") or audio_file:
    # ìŒì„± íŒŒì¼ì´ ìˆìœ¼ë©´ Whisper APIë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
    if audio_file is not None:
        transcript_result = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            language="ko"
        )
        transcript = transcript_result.text
        # í…ìŠ¤íŠ¸ ì…ë ¥ì´ ë¹„ì–´ìˆë‹¤ë©´ Whisper ê²°ê³¼ë¥¼ ì‚¬ìš©
        if not prompt:
            prompt = transcript
    combined_prompt = prompt.strip()

    # ìœ íš¨í•œ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ì²˜ë¦¬
    if combined_prompt:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° ì¶œë ¥ (ì²¨ë¶€ ì´ë¯¸ì§€ í¬í•¨)
        st.session_state.messages.append({"role": "user", "content": combined_prompt})
        with st.chat_message("user"):
            st.markdown(combined_prompt)
            if st.session_state.get("uploaded_image_data"):
                st.image(st.session_state["uploaded_image_data"], width=150, caption="ì²¨ë¶€ëœ ì´ë¯¸ì§€")

        # Pinecone ê²€ìƒ‰
        query_embedding = get_embedding(combined_prompt)
        results = index.query(vector=query_embedding, top_k=3, include_metadata=True)
        pinecone_context = ""
        displayed_image = None
        for match in results["matches"]:
            metadata = match["metadata"]
            pinecone_context += (
                f"Section: {metadata.get('section_title', '')}\n"
                f"Content: {metadata.get('content', '')}\n\n"
            )
            if not displayed_image and "image_paths" in metadata and metadata["image_paths"]:
                displayed_image = metadata["image_paths"][0]

        # ChatGPT í˜¸ì¶œ ë° ì‘ë‹µ ì¶œë ¥
        with st.chat_message("assistant"):
            response = ask_chatgpt_stream(combined_prompt, pinecone_context)
            if response.strip():
                try:
                    tts = gTTS(response, lang='ko')
                    audio_fp = io.BytesIO()
                    tts.write_to_fp(audio_fp)
                    audio_fp.seek(0)
                    st.audio(audio_fp, format="audio/mp3")
                except Exception as tts_error:
                    st.error(f"TTS ì—ëŸ¬: {tts_error}")

            if displayed_image:
                st.image(displayed_image, caption="ê´€ë ¨ ì´ë¯¸ì§€", use_container_width=True)

        st.session_state.messages.append({"role": "assistant", "content": response})

    # ë©”ì‹œì§€ ì²˜ë¦¬ í›„ ì—…ë¡œë” ìœ„ì ¯ê³¼ ì €ì¥ëœ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”
    st.session_state["uploader_reset"] += 1
    st.session_state["uploaded_image_data"] = None
