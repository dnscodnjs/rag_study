# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ëª¨ë“ˆ ì„í¬íŠ¸
from openai import OpenAI  # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ OpenAI í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸ (êµ¬ë²„ì „)
import openai  # ìµœì‹  OpenAI ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©
import streamlit as st  # ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ê¸° ìœ„í•œ Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os  # ìš´ì˜ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥(ì˜ˆ: í™˜ê²½ ë³€ìˆ˜, íŒŒì¼ ê²½ë¡œ ë“±) ì‚¬ìš©ì„ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
import base64  # ì´ë¯¸ì§€ë‚˜ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì¸ì½”ë”©/ë””ì½”ë”©í•˜ê¸° ìœ„í•œ base64 ëª¨ë“ˆ ì„í¬íŠ¸
import json  # JSON ë°ì´í„° ì½ê¸°/ì“°ê¸°ë¥¼ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
from dotenv import load_dotenv  # .env íŒŒì¼ì— ì €ì¥ëœ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•œ í•¨ìˆ˜ ì„í¬íŠ¸
import hashlib  # íŒŒì¼ì˜ í•´ì‹œê°’ ê³„ì‚°(ë¬´ê²°ì„± ê²€ì‚¬ ë“±)ì„ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
import io  # ë©”ëª¨ë¦¬ ë‚´ íŒŒì¼ ê°ì²´ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
from gtts import gTTS  # í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” gTTS (Google Text-to-Speech) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import re  # ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸

# LangChain, LangGraph, Pinecone ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from langchain_openai import OpenAIEmbeddings, ChatOpenAI  # OpenAI ì„ë² ë”©ê³¼ ì±„íŒ… ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
from langchain_core.prompts import PromptTemplate  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ìƒì„±í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
from langchain_community.tools import TavilySearchResults  # ì»¤ë®¤ë‹ˆí‹° ë„êµ¬ ì¤‘ ì›¹ ê²€ìƒ‰ ê´€ë ¨ ë„êµ¬ ì„í¬íŠ¸
from langchain.tools import tool  # LangChainì˜ ë„êµ¬(í•¨ìˆ˜)ë¥¼ ë°ì½”ë ˆì´í„° ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
from langchain_pinecone import PineconeVectorStore  # Pinecone ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
from langchain.docstore.document import Document  # ë¬¸ì„œ ê°ì²´ ìƒì„±ì— ì‚¬ìš©ë˜ëŠ” Document í´ë˜ìŠ¤ ì„í¬íŠ¸
from langchain_core.messages import HumanMessage  # ëŒ€í™”ì—ì„œ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í´ë˜ìŠ¤ ì„í¬íŠ¸
from langgraph.prebuilt import create_react_agent  # ì‚¬ì „ êµ¬ì¶•ëœ React ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ ì„í¬íŠ¸
from langgraph.graph import StateGraph, MessagesState, START, END  # ëŒ€í™” ìƒíƒœ íë¦„(ê·¸ë˜í”„) ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from langgraph.types import Command  # ìƒíƒœ ì „í™˜ ëª…ë ¹(Command) ê´€ë ¨ íƒ€ì… ì„í¬íŠ¸
from pinecone import Pinecone  # ìµœì‹  Pinecone API ì‚¬ìš©ì„ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
from typing import Literal  # íƒ€ì… íŒíŒ…ì„ ìœ„í•œ Literal ì„í¬íŠ¸
from typing_extensions import List  # íƒ€ì… íŒíŒ…ì„ ìœ„í•œ List ì„í¬íŠ¸

# ==========================================
# ì„¤ì • ë° ì´ˆê¸°í™”
# ==========================================
load_dotenv()  # .env íŒŒì¼ì— ì •ì˜ëœ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ì—¬ API í‚¤ ë“± í•„ìš”í•œ ê°’ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•¨

# OpenAI í´ë¼ì´ì–¸íŠ¸ì™€ ìµœì‹  openai ëª¨ë“ˆì˜ API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì™€ ì„¤ì •
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
openai.api_key = os.getenv("OPENAI_API_KEY")

# ê¸°ë³¸ ì„¤ì • ê°’ ì •ì˜
index_name = "test"  # Pineconeì— ìƒì„±í•  ì¸ë±ìŠ¤ ì´ë¦„
car_type = "EQS"  # ì°¨ëŸ‰ ì¢…ë¥˜ (ì˜ˆ: Mercedes Benz EQS)
IMAGE_PATTERN = r'(https?://\S+\.(?:png|jpg|jpeg|gif))'  # í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ì´ë¯¸ì§€ URLì„ ì°¾ê¸° ìœ„í•œ ì •ê·œí‘œí˜„ì‹

# OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (ì˜ˆ: text-embedding-3-large ëª¨ë¸ ì‚¬ìš©)
embedding = OpenAIEmbeddings(model="text-embedding-3-large")
# Pinecone ë²¡í„° ìŠ¤í† ì–´ ìƒì„±: ì§€ì •í•œ ì¸ë±ìŠ¤ ì´ë¦„ê³¼ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©
database = PineconeVectorStore(index_name=index_name, embedding=embedding)
# ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ retriever ê°ì²´ ìƒì„± (ìµœëŒ€ 3ê°œì˜ ê´€ë ¨ ë¬¸ì„œ ë°˜í™˜)
retriever = database.as_retriever(search_kwargs={"k": 3})
# OpenAIì˜ gpt-3.5-turbo ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì±„íŒ… ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
llm = ChatOpenAI(model='gpt-3.5-turbo')

# Streamlit í˜ì´ì§€ ì„¤ì •: í˜ì´ì§€ ì œëª©ê³¼ ë ˆì´ì•„ì›ƒì„ ì§€ì •
st.set_page_config(page_title="KCC Auto Manager", layout="wide")
st.title("KCC Auto Manager")  # í˜ì´ì§€ ìƒë‹¨ì— ì œëª© ì¶œë ¥

# í˜ì´ì§€ ë‚´ CSS ìŠ¤íƒ€ì¼ ì •ì˜: ë°˜ì‘í˜• ì´ë¯¸ì§€ í¬ê¸°, ë©”ë‰´ ë° í—¤ë”/í‘¸í„° ìˆ¨ê¹€ ì²˜ë¦¬
st.markdown(
    """
    <style>
    @media (max-width: 768px) {
        .responsive-image {
            width: 85% !important;
        }
    }
    @media (min-width: 769px) {
        .responsive-image {
            width: 50% !important;
        }
    }
    /* ê¸°ë³¸ í—¤ë”, í‘¸í„°, ë©”ë‰´ ìˆ¨ê¸°ê¸° */
    #MainMenu {visibility: hidden;}
    header {visibility: hidden;}
    footer {visibility: hidden;}
    </style>
    """,
    unsafe_allow_html=True
)

# Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”: ëŒ€í™” ê¸°ë¡ê³¼ ë§ˆì§€ë§‰ìœ¼ë¡œ ì¶œë ¥í•œ ë©”ì‹œì§€ ì¸ë±ìŠ¤ë¥¼ ì €ì¥
if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_displayed" not in st.session_state:
    st.session_state.last_displayed = 0

# ==========================================
# ì‚¬ì´ë“œë°” ì„¤ì •
# ==========================================
with st.sidebar:
    st.title("ğŸ¤—ğŸ’¬ Auto Manager ğŸš—")  # ì‚¬ì´ë“œë°” ì œëª©
    st.subheader("í˜„ì¬ ì°¨ëŸ‰: ë²¤ì¸  S í´ë˜ìŠ¤")  # í˜„ì¬ ì°¨ëŸ‰ ì •ë³´ ì¶œë ¥
    st.markdown("### ì„¤ì •")
    # ì‚¬ìš©ìì—ê²Œ ì„ íƒ ê°€ëŠ¥í•œ ì–¸ì–´ ì˜µì…˜ ì œê³µ (í•œêµ­ì–´, English, Deutsch)
    user_language = st.selectbox("ì‚¬ìš© ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”", ("í•œêµ­ì–´", "English", "Deutsch"))
    st.markdown(f"ì„ íƒëœ ì–¸ì–´: **{user_language}**")
    st.markdown("### ë°”ë¡œê°€ê¸°")
    # Mercedes-Benz ê³µì‹ í™ˆí˜ì´ì§€ ë§í¬ ì¶”ê°€
    st.markdown("[ë©”ë¥´ì„¸ë°ìŠ¤-ë²¤ì¸  ê³µì‹ í™ˆí˜ì´ì§€](https://www.mercedes-benz.co.kr/)")

# ==========================================
# ë°ì´í„° ì¸ë±ì‹± ê´€ë ¨ í•¨ìˆ˜ë“¤
# ==========================================
def get_file_hash(filename):
    """
    íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ SHA-256 í•´ì‹œê°’ì„ ê³„ì‚°í•˜ì—¬ ë°˜í™˜.
    ì´ë¥¼ í†µí•´ íŒŒì¼ì˜ ë³€ê²½ ì—¬ë¶€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŒ.
    """
    h = hashlib.sha256()
    with open(filename, 'rb') as f:
        h.update(f.read())
    return h.hexdigest()

def load_stored_hash(hash_file):
    """
    ì €ì¥ëœ í•´ì‹œê°’ì„ ì§€ì •ëœ íŒŒì¼ì—ì„œ ì½ì–´ ë°˜í™˜.
    íŒŒì¼ì´ ì—†ìœ¼ë©´ Noneì„ ë°˜í™˜.
    """
    try:
        with open(hash_file, "r", encoding="utf-8") as f:
            return f.read().strip()
    except FileNotFoundError:
        return None

def save_hash(hash_file, hash_value):
    """
    ê³„ì‚°ëœ í•´ì‹œê°’ì„ ì§€ì •ëœ íŒŒì¼ì— ì €ì¥.
    """
    with open(hash_file, "w", encoding="utf-8") as f:
        f.write(hash_value)

def index_data():
    """
    'usage.json' íŒŒì¼ì˜ ë°ì´í„°ë¥¼ ì½ì–´ì™€ ë¬¸ì„œ(Document) ê°ì²´ë¡œ ë³€í™˜í•œ í›„,
    Pinecone ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜.
    ì´ì „ì— ì €ì¥ëœ í•´ì‹œê°’ê³¼ ë¹„êµí•˜ì—¬ íŒŒì¼ ë‚´ìš©ì´ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ì¬ì¸ë±ì‹± ìˆ˜í–‰.
    """
    hash_file = "usage.json.hash"
    current_hash = get_file_hash("usage.json")
    stored_hash = load_stored_hash(hash_file)
    
    if stored_hash != current_hash:
        # JSON íŒŒì¼ì„ ì—´ì–´ ë°ì´í„° ë¡œë“œ
        with open("usage.json", "r", encoding="utf-8") as f:
            test_data = json.load(f)

        documents = []
        # JSON ë°ì´í„°ì˜ ê° í•­ëª©ì— ëŒ€í•´ ë¬¸ì„œ ìƒì„±
        for item in test_data:
            pdf_file = item.get("pdf_file", "")
            structure = item.get("structure", [])
            for section in structure:
                title = section.get("title", "")
                sub_titles = section.get("sub_titles", [])
                content_text = title  # ì„¹ì…˜ ì œëª©ì„ ê¸°ë³¸ ë‚´ìš©ìœ¼ë¡œ ì„¤ì •
                image_paths = []
                for sub in sub_titles:
                    sub_title = sub.get("title", "")
                    contents = sub.get("contents", [])
                    # ë‚´ìš© ì¤‘ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ(íŒŒì¼ í™•ì¥ìë¡œ íŒë³„) ì¶”ì¶œ
                    for content in contents:
                        if content.lower().endswith(('.jpeg', '.jpg', '.png', '.gif')):
                            image_paths.append(content)
                    # 'images' í‚¤ì— í¬í•¨ëœ ì´ë¯¸ì§€ URLë„ ì¶”ê°€
                    for img_url in sub.get("images", []):
                        if isinstance(img_url, str):
                            image_paths.append(img_url)
                    # ì´ë¯¸ì§€ê°€ ì•„ë‹Œ í…ìŠ¤íŠ¸ ë‚´ìš©ë§Œ ë”°ë¡œ ì¶”ê°€
                    non_image_contents = [c for c in contents if not c.lower().endswith(('.jpeg', '.jpg', '.png', '.gif'))]
                    content_text += "\n" + sub_title + "\n" + "\n".join(non_image_contents)
                # ë©”íƒ€ë°ì´í„° ìƒì„± (PDF íŒŒì¼ëª…, ì„¹ì…˜ ì œëª©, ì´ë¯¸ì§€ ê²½ë¡œ ëª©ë¡)
                metadata = {
                    "pdf_file": pdf_file,
                    "section_title": title,
                    "image_paths": json.dumps(image_paths)
                }
                # Document ê°ì²´ ìƒì„± í›„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                documents.append(Document(page_content=content_text, metadata=metadata))
        # ìƒì„±ëœ ë¬¸ì„œë¥¼ Pinecone ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€
        database.add_documents(documents)
        # ìƒˆ í•´ì‹œê°’ì„ ì €ì¥í•˜ì—¬ ì´í›„ ë³€ê²½ ì—¬ë¶€ë¥¼ íŒë‹¨
        save_hash(hash_file, current_hash)

# Pinecone ì´ˆê¸°í™”: í™˜ê²½ë³€ìˆ˜ì— ì €ì¥ëœ API í‚¤ ì‚¬ìš©
pinecone_api_key = os.getenv("PINECONE_API_KEY")
pc = Pinecone(api_key=pinecone_api_key)

# Pinecone ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” í™•ì¸: ì§€ì •í•œ ì´ë¦„ì˜ ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
if index_name not in [idx.name for idx in pc.list_indexes()]:
    pc.create_index(
        name=index_name,
        dimension=3072,  # ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì› (ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¦„)
        metric="cosine",  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ê°„ ìœ ì‚¬ë„ ê³„ì‚°
    )
index = pc.Index(index_name)

# ë°ì´í„° ì¸ë±ì‹± ì§„í–‰ (ìŠ¤í”¼ë„ˆë¥¼ í†µí•´ ì§„í–‰ ìƒí™© í‘œì‹œ)
with st.spinner("ë°ì´í„° ì¸ë±ì‹± ì¤‘..."):
    index_data()

# ==========================================
# LangGraph ì •ì˜ ë° ì—ì´ì „íŠ¸ ì„¤ì •
# ==========================================

# LangChain ë„êµ¬ ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ê²€ìƒ‰ ë„êµ¬ ì •ì˜
@tool
def vector_retrieve_tool(query: str) -> List[Document]:
    """
    ì…ë ¥ëœ ì¿¼ë¦¬ì— ê¸°ë°˜í•˜ì—¬ Pinecone ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜.
    ë°˜í™˜ê°’ì€ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸.
    """
    return retriever.invoke(query)

def retrieve_search_node(state: MessagesState) -> Command:
    """
    LangGraphì˜ ìƒíƒœ ë…¸ë“œ ì¤‘ í•˜ë‚˜ë¡œ, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë‚´ë¶€ ê²€ìƒ‰(ë²¡í„° ê²€ìƒ‰)ì„ ìˆ˜í–‰í•˜ê³ 
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    - ê²€ìƒ‰ ì—ì´ì „íŠ¸ëŠ” ì°¨ëŸ‰ ë§¤ë‰´ì–¼ ì „ë¬¸ê°€ ì—­í• ì„ í•˜ë©°, ì‚¬ì‹¤ ê¸°ë°˜ì˜ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    - ìƒì„±ëœ ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ë²ˆì—­ë©ë‹ˆë‹¤.
    - ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    retrieve_search_agent = create_react_agent(
        llm, 
        tools=[vector_retrieve_tool],
        state_modifier=(
            "You are an expert on Mercedes Benz " + car_type + " car manuals. "
            "Please consider the information you provided and reply. Provide factual answers, not opinions. "
            "Translate the answers into Korean. "
            "Refer to the structure below to organize the website information:\n\n"
            "{{ì œëª©}}\nExample: Mercedes Benz EQS: Driver Display Charge Status Window Function\n\n"
            "{{ì£¼ìš” ì •ë³´}}\n- Feature Summary and Key Points\n\n"
            "{{ìƒì„¸ ì„¤ëª…}}\n- Detailed description of features\n\n"
        )
    )
    # ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ ìƒì„±
    result = retrieve_search_agent.invoke(state)
    # ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ë§ˆì§€ë§‰ ë©”ì‹œì§€ì˜ ë‚´ìš©ì„ ì €ì¥
    state["retrieve_result"] = result['messages'][-1].content

    # ì‚¬ìš©ìì˜ ì…ë ¥(ì²« ë©”ì‹œì§€)ì„ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰
    user_query = state["messages"][0].content
    docs = retriever.invoke(user_query)
    
    displayed_image = None
    # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë©”íƒ€ë°ì´í„°ì— ì €ì¥ëœ ì´ë¯¸ì§€ ê²½ë¡œê°€ ìˆëŠ” ê²½ìš°, ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ ì„ íƒ
    for doc in docs:
        meta = doc.metadata
        if "image_paths" in meta and meta["image_paths"]:
            try:
                image_paths = json.loads(meta["image_paths"])
            except Exception:
                image_paths = meta["image_paths"]
            if isinstance(image_paths, list) and image_paths:
                displayed_image = image_paths[0]
                break

    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€ (ëŒ€í™” íë¦„ì— ì‚¬ìš©)
    state.setdefault("messages", []).append(
        HumanMessage(content=state["retrieve_result"], name="retrieve_search")
    )
    return Command(update={'messages': state["messages"]})

def evaluate_node(state: MessagesState) -> Command[Literal['web_search', END]]:
    """
    LangGraph ìƒíƒœ ë…¸ë“œë¡œ, ìƒì„±ëœ ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ë¶„í•œì§€ í‰ê°€í•©ë‹ˆë‹¤.
    
    - ë§Œì•½ ìƒì„±ëœ ë‹µë³€ì˜ ë‚´ìš©ì´ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´(ì˜ˆ: 200ì ì´í•˜) ì›¹ ê²€ìƒ‰ ë…¸ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.
    - ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ëŒ€í™” íë¦„ì„ ì¢…ë£Œ(END)í•©ë‹ˆë‹¤.
    """
    if state["messages"][-1].content is None:
        st.write("ë‹µë³€ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        return Command(goto='web_search')

    # í‰ê°€ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±: ë‹µë³€ì˜ ê¸¸ì´ì— ë”°ë¼ 'yes' ë˜ëŠ” 'no'ë¥¼ ë°˜í™˜í•˜ë„ë¡ í•¨
    eval_prompt = PromptTemplate.from_template(
        "You are an expert on Mercedes Benz " + car_type + " car manuals. "
        "Please rate if the retrive results below provide sufficient answers. "
        "If the answer has more than 200 characters of detailed info, answer 'no'. Otherwise, answer 'yes'.\n\n"
        "Retrieve Results:\n{result}"
    )
    eval_chain = eval_prompt | llm
    evaluation = eval_chain.invoke({"result": state.get("retrieve_result")})
    if "yes" in evaluation.content.lower():
        st.write("ë‹µë³€ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        return Command(goto='web_search')
    else:
        return Command(goto=END)

def web_search_node(state: MessagesState) -> Command:
    """
    LangGraph ìƒíƒœ ë…¸ë“œë¡œ, ì›¹ ê²€ìƒ‰ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ë³´ë‹¤ ìƒì„¸í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    - ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ëŠ” ì „ë¬¸ê°€ ì—­í• ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ë©°, 
      ì •í•´ì§„ í…œí”Œë¦¿ êµ¬ì¡°(ì œëª©, ì£¼ìš” ì •ë³´, ìƒì„¸ ì„¤ëª…)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
    - ìƒì„±ëœ ì›¹ ê²€ìƒ‰ ê²°ê³¼ëŠ” ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€ë©ë‹ˆë‹¤.
    """
    tavily_search_tool = TavilySearchResults(   
        max_results=5,
        search_depth="advanced",
        include_answer=True,
        include_raw_content=True,
        include_images=True,
    )
    web_search_agent = create_react_agent(
        llm, 
        tools=[tavily_search_tool],
        state_modifier=(
            "You are an expert on Mercedes Benz " + car_type + " car manuals. "
            "Reply with detailed website information. Translate the answer into Korean. "
            "Use the following structure:\n\n"  
            "## {{ì œëª©}}\nExample: Mercedes Benz EQS: Driver Display Charge Status Window Function\n\n"
            "### {{ì£¼ìš” ì •ë³´}}\n- Feature Summary and Key Points\n\n"
            "### {{ìƒì„¸ ì„¤ëª…}}\n- Detailed description of the feature. / {{ì¶œì²˜}}: real website link\n\n"
            "ê° í•­ëª©ì€ ë³„ë„ ì¤„ë¡œ êµ¬ë¶„í•´ ì¶œë ¥í•´ì£¼ì„¸ìš”."
        )
    )
    # ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ ìƒì„±
    result = web_search_agent.invoke(state)
    state["web_result"] = result['messages'][-1].content
    # ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    state.setdefault("messages", []).append(
        HumanMessage(content=state["web_result"], name="web_search")
    )
    return Command(update={'messages': state["messages"]})

# ==========================================
# ê·¸ë˜í”„ êµ¬ì„± (ëŒ€í™” íë¦„ ì œì–´)
# ==========================================
graph_builder = StateGraph(MessagesState)
# ê° ìƒíƒœ ë…¸ë“œë¥¼ ê·¸ë˜í”„ì— ì¶”ê°€
graph_builder.add_node("retrieve_search", retrieve_search_node)
graph_builder.add_node("evaluate", evaluate_node)
graph_builder.add_node("web_search", web_search_node)

# ë…¸ë“œ ê°„ ì „ì´ ì„¤ì •: ì‹œì‘ -> ê²€ìƒ‰ -> í‰ê°€ -> (ì›¹ ê²€ìƒ‰ ë˜ëŠ” ì¢…ë£Œ)
graph_builder.add_edge(START, "retrieve_search")
graph_builder.add_edge("retrieve_search", "evaluate")
graph_builder.add_edge("web_search", END)

# ìµœì¢… ê·¸ë˜í”„ ì»´íŒŒì¼
graph = graph_builder.compile()

def ask_lang_graph_agent(query):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸(query)ì„ ë°›ì•„ LangGraph ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ì „ì²´ ëŒ€í™” íë¦„ì— ë”°ë¥¸ ì‘ë‹µì„ ìƒì„±.
    """
    return graph.invoke({"messages": [("user", query)]})

# ==========================================
# ì‚¬ìš©ì ì…ë ¥ ë° ì²˜ë¦¬
# ==========================================
# ì‚¬ìš©ìë¡œë¶€í„° ì±„íŒ… ì…ë ¥ì„ ë°›ìŒ (í…ìŠ¤íŠ¸ ì…ë ¥ì°½)
user_prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

# ìŒì„± ì…ë ¥ê³¼ ì´ë¯¸ì§€ ì—…ë¡œë“œë¥¼ ìœ„í•œ í™•ì¥ ì˜ì—­ ì œê³µ
with st.expander("ìŒì„± ì…ë ¥ ë° ì´ë¯¸ì§€ ì²¨ë¶€ ì—´ê¸°"):
    audio_file = st.audio_input("ìŒì„±ì„ ë…¹ìŒí•˜ì„¸ìš”")
    uploaded_image = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png", "jpg", "jpeg", "gif"])

# ìŒì„± íŒŒì¼ì´ ìˆëŠ” ê²½ìš°: OpenAIì˜ Whisper ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
if audio_file is not None:
    with st.spinner("ìŒì„± ì¸ì‹ ì¤‘..."):
        transcript_result = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            language="ko"
        )
    user_prompt = transcript_result.text

# ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸ ì…ë ¥ ë˜ëŠ” ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•œ ê²½ìš° ì²˜ë¦¬
if user_prompt or uploaded_image:
    # ì‚¬ìš©ì ì…ë ¥ëœ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ê²°í•©í•˜ì—¬ í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ë¡œ êµ¬ì„±
    combined_prompt = user_prompt or ""
    
    # ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œëœ ê²½ìš°, í™”ë©´ì— í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ í‘œì‹œ
    if uploaded_image:
        st.image(uploaded_image, width=150, caption="ì²¨ë¶€ëœ ì´ë¯¸ì§€")

    # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœ(ëŒ€í™” ê¸°ë¡)ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": combined_prompt})
    
    # LangGraph ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„± (ì²˜ë¦¬ ì¤‘ ìŠ¤í”¼ë„ˆ í‘œì‹œ)
    with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        response = ask_lang_graph_agent(combined_prompt)
    
    # assistant_responseì— ì—ì´ì „íŠ¸ì˜ ì‘ë‹µ ì €ì¥
    assistant_response = response

    # ì´í›„ assistant_responseë¥¼ í™œìš©í•˜ì—¬ ì¶”ê°€ ì²˜ë¦¬(ì˜ˆ: ì´ë¯¸ì§€ ì¶”ì¶œ, TTS ë³€í™˜ ë“±)ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŒ.
    # ì—¬ê¸°ì„œëŠ” ì½”ë“œê°€ ì¤‘ë‹¨ëœ ë¶€ë¶„ì´ë¯€ë¡œ, í›„ì† ì²˜ë¦¬ ì½”ë“œê°€ ì¶”ê°€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
