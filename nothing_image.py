from openai import OpenAI  # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ OpenAI í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸
import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os  # ìš´ì˜ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥ì„ ìœ„í•œ os ëª¨ë“ˆ ì„í¬íŠ¸
from dotenv import load_dotenv  # .env íŒŒì¼ì˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•œ load_dotenv í•¨ìˆ˜ ì„í¬íŠ¸

load_dotenv()  # .env íŒŒì¼ì— ì €ì¥ëœ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

# OpenAI API í´ë¼ì´ì–¸íŠ¸ ìƒì„±, í™˜ê²½ë³€ìˆ˜ì—ì„œ OPENAI_API_KEYë¥¼ ì½ì–´ì˜´
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)

st.set_page_config(page_title="KCC Auto Manager ğŸš—", layout="centered")
st.title("KCC Auto Manager ğŸš—")
st.caption("ìë™ì°¨ ì‚¬ìš© ë§¤ë‰´ì–¼ ë° ì„œë¹„ìŠ¤ ì„¼í„° ìœ„ì¹˜ ì°¾ê¸°ë¥¼ ë„ì™€ë“œë¦½ë‹ˆë‹¤!")

# ì„¸ì…˜ ìƒíƒœì— ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ë¯¸ì§€ ì—…ë¡œë” í‘œì‹œ ì—¬ë¶€ í”Œë˜ê·¸ ì´ˆê¸°í™”
if "show_uploader" not in st.session_state:
    st.session_state.show_uploader = False

# ì´ì „ ëŒ€í™” ë‚´ìš©ì´ ìˆë‹¤ë©´ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œ   
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ChatGPTì—ê²Œ ì§ˆë¬¸ì„ ë³´ë‚´ê³  ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ëŠ” í•¨ìˆ˜ (ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨)
def ask_chatgpt_stream(question):
    try:
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í¬í•¨í•œ ì „ì²´ ëŒ€í™” ì´ë ¥ì„ êµ¬ì„±
        conversation = [{"role": "system", "content": "ë„ˆëŠ” ë²¤ì¸  S-class ì‚¬ìš© ë©”ë‰´ì–¼ì— ëŒ€í•´ ì „ë¬¸ê°€ì•¼."}]
        conversation.extend(st.session_state.messages)
        conversation.append({"role": "user", "content": question})
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",  # ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
            messages=conversation,
            stream=True  # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ í™œì„±í™”
        )

        answer_container = st.empty()
        full_response = ""
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²­í¬ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
        for chunk in response:
            if chunk.choices[0].delta.content is not None:
                full_response += chunk.choices[0].delta.content
                answer_container.markdown(full_response)
        return full_response

    except Exception as e:
        st.error(f"Error: {str(e)}")
    return ""

# í•˜ë‹¨ ì˜ì—­: í…ìŠ¤íŠ¸ ì…ë ¥ê³¼ ì´ë¯¸ì§€ ì²¨ë¶€ ì•„ì´ì½˜ì„ ê°™ì€ í–‰ì— ë°°ì¹˜
col_text, col_attach = st.columns([4, 1])

with col_text:
    prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")  # ì±„íŒ… ì…ë ¥ì¹¸

with col_attach:
    # ì²¨ë¶€ ì•„ì´ì½˜ ë²„íŠ¼ (í´ë¦­ ì‹œ ì´ë¯¸ì§€ ì—…ë¡œë” í‘œì‹œ)
    if st.button("ğŸ“"):
        st.session_state.show_uploader = True

# ì´ë¯¸ì§€ ì—…ë¡œë”ê°€ í™œì„±í™”ëœ ê²½ìš° í‘œì‹œ
if st.session_state.show_uploader:
    uploaded_image = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=["png", "jpg", "jpeg"])
    if uploaded_image is not None:
        st.image(uploaded_image, caption="ì²¨ë¶€ëœ ì´ë¯¸ì§€", use_column_width=True)
        # ì—…ë¡œë“œ í›„ ë²¡í„° DB ê²€ìƒ‰ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
        st.session_state.show_uploader = False

# í…ìŠ¤íŠ¸ ì…ë ¥ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
if prompt:
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µ ë©”ì‹œì§€ ì²˜ë¦¬ (ìŠ¤íŠ¸ë¦¬ë°)
    with st.chat_message("assistant"):
        response = ask_chatgpt_stream(prompt)
    st.session_state.messages.append({"role": "assistant", "content": response})
